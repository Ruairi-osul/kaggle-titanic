{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from sklearn_utils.preprocessing import ColumnSelector, ColumnDropper, DTypeTransformer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.base import clone\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_pipeline_steps(search_dict, name):\n",
    "    res = {f\"{name}__{key}\": val for key, val in search_dict.items()}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\".\").absolute().parent / \"data\"\n",
    "data = pd.read_csv(data_dir / \"train.csv\")\n",
    "X = data[[c for c in data.columns if c != \"Survived\"]]\n",
    "y = data[[\"Survived\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLS = [\"Fare\", \"Age\"]\n",
    "NOM_COLS = [\"Sex\", \"Embarked\"]\n",
    "ORD_COLS = [\"Pclass\"]\n",
    "ALL_COLS = NUM_COLS + NOM_COLS + ORD_COLS \n",
    "\n",
    "# select columns\n",
    "c_selector = ColumnSelector(ALL_COLS)\n",
    "\n",
    "# nominal_pipeline\n",
    "nom_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encode\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "# ordinal_pipeline\n",
    "ord_pipe = Pipeline([\n",
    "    (\"encode\", OrdinalEncoder(categories=[[1, 2, 3,]])),\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "])\n",
    "\n",
    "# numeric pipeline\n",
    "num_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [(\"nom\", nom_pipe, NOM_COLS),\n",
    "    (\"ord\", ord_pipe, ORD_COLS),\n",
    "    (\"num\", num_pipe, NUM_COLS)],\n",
    ")\n",
    "\n",
    "pp_pipe = Pipeline([\n",
    "    (\"col_select\", c_selector),\n",
    "    (\"preprocess\", preprocessor),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Hyperparmeter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'logistic_regression',\n",
       "  'best_score': 0.7980136909437773,\n",
       "  'best_params': {'clf__C': 10, 'clf__penalty': 'l1'}},\n",
       " {'model': 'svm',\n",
       "  'best_score': 0.8338345864661655,\n",
       "  'best_params': {'clf__C': 1, 'clf__kernel': 'rbf'}},\n",
       " {'model': 'naive_bayes', 'best_score': 0.7740769835035349, 'best_params': {}},\n",
       " {'model': 'random_forrest',\n",
       "  'best_score': 0.8128268432274716,\n",
       "  'best_params': {'clf__max_depth': 32, 'clf__n_estimators': 100}},\n",
       " {'model': 'adaboost',\n",
       "  'best_score': 0.8189541016720906,\n",
       "  'best_params': {'clf__learning_rate': 1, 'clf__n_estimators': 200}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posible_models = {\n",
    "    \"logistic_regression\": {\n",
    "        \"model\": LogisticRegression(solver=\"liblinear\"),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"penalty\": [\"l1\", \"l2\"]\n",
    "        }\n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"model\": SVC(),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10, 100],\n",
    "            \"kernel\": [\"linear\" ,\"poly\", \"rbf\"]\n",
    "        }\n",
    "    },\n",
    "    \"naive_bayes\": {\n",
    "        \"model\": GaussianNB(),\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"random_forrest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200, 500],\n",
    "            \"max_depth\": [None, 16, 32]\n",
    "        }\n",
    "    },\n",
    "    \"adaboost\": {\n",
    "        \"model\": AdaBoostClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [30, 50, 100, 200],\n",
    "            \"learning_rate\": [0.1, 1]\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "scores = []\n",
    "for mod_name, mod_params in posible_models.items():\n",
    "    pipe = clone(pp_pipe)\n",
    "    pipe.steps.append([\"clf\", mod_params[\"model\"]])\n",
    "    mod_params = prepend_pipeline_steps(\n",
    "        mod_params[\"params\"], \"clf\",\n",
    "    )\n",
    "    pipe = GridSearchCV(pipe, mod_params)\n",
    "    pipe.fit(X_train, np.ravel(y_train))\n",
    "    scores.append({\n",
    "        \"model\": mod_name,\n",
    "        \"best_score\": pipe.best_score_,\n",
    "        \"best_params\": pipe.best_params_,\n",
    "    })\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling best models together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"logreg\", LogisticRegression(C=0.1, penalty= 'l2')),\n",
    "    (\"svm\", SVC(C=1, kernel=\"rbf\")),\n",
    "    (\"naive_bayes\", GaussianNB()),\n",
    "    (\"rforrest\", RandomForestClassifier(max_depth=16)),\n",
    "    (\"adaboost\", AdaBoostClassifier(n_estimators=200))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026905829596412"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = clone(pp_pipe)\n",
    "voting_clf.steps.append([\"clf\", VotingClassifier(estimators, n_jobs=-1)])\n",
    "voting_clf.fit(X_train, np.ravel(y_train))\n",
    "voting_score = voting_clf.score(X_test, y_test)\n",
    "voting_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7937219730941704"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_clf = clone(pp_pipe)\n",
    "stacking_clf.steps.append([\"clf\", StackingClassifier(estimators, n_jobs=-1)])\n",
    "stacking_clf.fit(X_train, np.ravel(y_train))\n",
    "stacking_score = stacking_clf.score(X_test, np.ravel(y_test))\n",
    "stacking_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_dir / \"test.csv\")\n",
    "stacking_clf = clone(pp_pipe)\n",
    "stacking_clf.steps.append([\"clf\", StackingClassifier(estimators, n_jobs=-1)])\n",
    "stacking_clf.fit(X, np.ravel(y))\n",
    "\n",
    "predictions = stacking_clf.predict(test_data)\n",
    "df_out = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": predictions})\n",
    "df_out.to_csv(data_dir / \"pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
